\begin{figure*}
	\begin{center}
		\fbox{\includegraphics[scale=1.5]{./images/tensorboards}}
		\begin{center}
			\caption{Tensorboard graph of experiments, from left to right: \textbf{Validation Accurancy over epochs}, \textbf{Valdiation error over epochs}. }
			\label{fig:tensorboard}
		\end{center}
		\vspace{-25pt}
	\end{center}
\end{figure*}
\section{Experiments}
\begin{figure}
	\begin{center}
		\fbox{\includegraphics[scale=0.167]{./images/normal_3159}
			\includegraphics[scale=0.167]{./images/segmented_3159}
			\includegraphics[scale=0.2241]{./images/9_ROTATE_180_crop}
			\includegraphics[scale=0.167]{./images/196_ROTATE_270}
			\includegraphics[scale=0.2241]{./images/random_backgorund}
		}
		\begin{center}
			\caption{Samples of dataset images, from left to right: \textbf{Original PlantVillage}, \textbf{Segmented PlantVillage}, \textbf{Random Background Crop}, \textbf{Random Noise Background} and \textbf{Random Background Image}.}
			\label{fig:samples}
		\end{center}
		\vspace{-32pt}
	\end{center}
\end{figure}
Our experiments are about two main tasks: binary and multi-class classification. In this section, first we describe the dataset and the variations created to perform sensitivity analysis. Then we go trough the experiments setup where we describe how we have conducted the experiments to accomplish the two task and finally we show the results.
\subsection{Datasets}
We analyze 18,158 images of tomato plant leaves, which are split in 10 classes, 9 diseases and 1 healthy. The scope is to predict the correct class of a leaf image. All the images are sized 256x256 pixels. 
\\\indent Given the original dataset we have conducted the training phase on different variations of the original dataset, we have worked on the backgrounds in order to find a way to overcome the limits highlighted in \cite{ref33, ref10} and confirmed by us. Especially, we have found out a dependence between the original backgrounds and their belonging class.
In Figure \ref{fig:samples} we can see all the images and the different variations of the dataset that we have tested.
\begin{itemize}
	\item{\textbf{Original PlantVillage dataset.} It consists of images of tomato leaves laying over a gray table.}
	\vspace{-5pt}
	\item{\textbf{Segmented PlantVillage dataset.} It consists of images of tomato leaves with no background, this variation has been used also in \cite{ref10}. In our work we have re-segmented the images since in the available segmented dataset they were incomplete.}
	\vspace{-5pt}
	\item{\textbf{Random Background Crop dataset.} It consists of the leaf images coming from PlantVillage with a background composed of crops of background coming from the Original PlantVillage dataset.}
	\vspace{-5pt}
	\item{\textbf{Random Noise Background dataset.} It consists of leaf images coming from PlantVillage with a background composed of random colored pixels.}
	\vspace{-5pt}
	\item{\textbf{Random Background Image dataset.} It consists of leaf images coming from PlantVillage dataset with a background taken from a set of 4,176 images we have built by looking for tomato plantation pictures on the Internet. The objective of this set was not only to decouple the background influence on the classifier but also try to take the leaf in a situation similar to a realistic one, where the leaf image is taken directly in the plantation.}
\end{itemize}
\subsection{Experiments setup}
\subsubsection{Data augmentation and normalization}
We have performed data augmentation applying to the original sample two randomly selected transformations from this pool: Flip Top Bottom, Flip Left Right, Rotate 90\degree, Rotate 180\degree, Rotate 270\degree, Flip Top Bottom and Rotate 90\degree, Flip Top Bottom and Rotate 270\degree.
\\
Another key aspect of our setup is the normalization of the input images, indeed, the chosen normalization changes dramatically the model performance. In our work we have considered the following normalization approaches:
\\
\textbf{Dataset Normalization.} Given the chosen variation of the dataset we have computed the mean and the standard deviation of the train dataset.
\\
\textbf{Per-leaf Normalization.} Starting from the segmented train dataset we have computed the mean and standard deviation of the non-black pixels.
\subsubsection{Binary classification setup}
\textbf{LeNet architecture.} This network proposed in \cite{ref30} is the first and simplest deep model available. We have adapted it to perform our binary task.
\\
\textbf{Weights initialization.} For this network we have started using training from scratch approach. The weights in the network are initialized using Xavier initialization (\cite{ref31}). This helps the training since we start from a normally distributed set of weights and we avoid that certain weighs vanish through epochs.
\\
\textbf{Activation function.}
The layer activation functions is the rectified linear unit (ReLU) function since it diminishes the likelihood of a gradient to vanish.
\\
\textbf{Loss function.}
The chosen loss function for the binary classification is the binary cross-entropy since it is properly designed for binary tasks.
\\
\textbf{Validation.}
For this task we have performed 10-fold cross validation. This kind of validation has been used to estimate the hyper-parameters.
\subsubsection{Multi-class classification setup}
\textbf{AlexNet architecture.}
For this task we have chosen a more complex model since we have first tested LeNet architecture achieving results very far from the state-of-the-art \cite{ref11}.
\\
\textbf{Weights initialization.}
For this network we have tried both training from scratch approach and transfer learning. The weights in the first case are initialized using Xavier initialization (\cite{ref31}). In the transfer learning approach we have used the weights coming from the training on ImageNet \cite{imagenet}.
\\
\textbf{Activation function.}
Layers activation function is again the rectified linear unit (ReLU) function.
\\
\textbf{Loss function.}
In this case we have used cross-entropy as loss function since it is largely used for multi-class classification tasks.
=========================
\\
\textbf{Validation.}
in the case of Multi-class Classification we opt to proceed with cross validation. We have chosen a different approach from binary classification. In fact k-fold cross validation applied on AlexNet requires a lot of computing time that is not justified in our dataset since there is small amount of variance in our pictures and consequently in each possible fold.
\\
\textbf{Optimizer:}
As optimizer we have choosen Adam \cite{ref32}. An important annotation should be done about this optimizer. In fact trough the training process we noticed that accuracy after a bunch of epochs drops. This was caused by the $\varepsilon$ coefficient, this coefficient used to avoid division by zero when the gradient is almost zero in parameters update.  By default is set to $1*10^{-8}$ and it causes large weights updates. So we set it to 0.1 to avoid this problem.



\subsection{Results and discussion}
\subsubsection{Binary Classification}
After a training phase using 10-fold cross validation, we have selected as best hyperparameters for our binary classification problem, the batch size equal to 32 and the total number of epochs equal to 15. With this configuration, after retraining the net on the global train set, we have obtained the results on the test set shown in the table \ref{table:binary}. Beeing a very unbalanced dataset because of the number of healthy leaves with respect to the non healthy ones, we have expected to have an healthy accurancy lower than non healthy. The result shows that our assumptions was correct. In fact LeNet accurancy for healthy aren't good as for non healthy one. By the way the average performances of our net are good.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|}
			\hline
			\textbf{Measure} & \textbf{Results} \\ 
			\hline
			$Average Accuracy$ & $0.999184$ \\
			$Precision_M$ & $0.993377$ \\
			$Recall_M$ & $0.996678$ \\
			$F_1 score_M$ & $0.995025$ \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Performance of binary classification.}
	\label{table:binary}
\end{table}
\subsubsection{Multi-class Classification}
As we have done for binary classification, we have tried different run using different hyperparameters and we test our result on the validation set. As figure \ref{fig:tensorboard} shows, it's possible to understand that the best configuration it has been given from Alexnet pretrained, with batch size equal to 64, eps equal to 0.1 for 57 epochs. The results obtained from this configuration are described in the first row of the table \ref{table:sensitivity}. AlexNet pretrained has a very good performance for all the classes and obtained also better result than the state of the art \cite{ref11}. We have expected that classes with less samples, e.g. Tomato Mosaic Virus, would have been missclassified compared to classes with an higher number of samples, e.g. Tomato Yellow Leaf Curl. This does not happen in the reality, because our classifier missclassified only some samples that aren't related to the size of the class predicted.
\subsubsection{Sensitivity Analisys}
After having reached a good level of accuracy for our multi-class classification task, we have moved our attention to analise the robustness of our dataset by computing gradcam and occlusion methods to analise which parts of the leaf trigger the classifier. The table \ref{table:sensitivity} shows all the different approach we have tried. It's possible to see that the preformances of the results obtained are very far from the what we have done in the previous task. Sometimes also happens that some classes have never be predicted at all. Then we have tried a different way, applying both normalization and backgrounds moving to something similar to what a predictor will see when it will applied on the field. Using per-leaf normalization and random background images we obtain the result shows in figure \ref{fig:conf_matrix}. It is also possible to see in figure \ref{fig:gradcam} how the system is more robust to some background variation, activating only on the leaf surface.
\begin{table}
	\centering
	\small
	\begin{center}
		\begin{tabular}{|p{1.5cm}|p{1.5cm}|c|}
			\hline
			Train & Test & Performance\\ 
			\hline
			\multirow{4}*{Original}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.998560$ \\
					$Precision_M = 0.998339$ \\
					$Recall_M = 0.998173$ \\
					$F_1 score_M = 0.998254$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.390169$ \\
				$Precision_M = NaN$ \\
				$Recall_M = 0.285877$ \\
				$F_1 score_M = Nan$ \\
				\end{tabular} \\  				
			\hline
			\multirow{4}*{Segmented}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.617933$ \\
					$Precision_M = 0.730197$ \\
					$Recall_M = 0.494125$ \\
					$F_1 score_M = 0.486940$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.966511$ \\
				$Precision_M = 0.959517$ \\
				$Recall_M = 0.956894$ \\
				$F_1 score_M = 0.958019$ \\
				\end{tabular} \\  				
			\hline
			\multirow{4}*{Random Background Crop}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.769175$ \\
					$Precision_M = 0.794344$ \\
					$Recall_M = 0.673085$ \\
					$F_1 score_M = 0.671527$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.848037$ \\
				$Precision_M = 0.885544$ \\
				$Recall_M = 0.737432$ \\
				$F_1 score_M = 0.739969$ \\
				\end{tabular} \\  				
			\hline
			\multirow{4}*{Random Noise Background}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.578862$ \\
					$Precision_M = 0.666754$ \\
					$Recall_M = 0.490099$ \\
					$F_1 score_M = 0.499304$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.748469$ \\
				$Precision_M = 0.820938$ \\
				$Recall_M = 0.709873$ \\
				$F_1 score_M = 0.697417$ \\
				\end{tabular} \\  								
			\hline
		\end{tabular}
	\end{center}
	\caption{Performance of multi-class classification with difference training and test sets. We use a NaN value for the class that are never predicted to avoid division by zero in precision, recall and F1 score.}
	\label{table:sensitivity}
\end{table}
\begin{figure}[t]
	\begin{center}
		\fbox{\includegraphics[scale=0.3]{./images/conf_matrix_norm}}
	\end{center}
	\caption{Confusion matrix of AlexNet pretrained in multi-class classification problem in percentage using per-leaf normalization and random background images.}
	\label{fig:conf_matrix}
	\label{fig:long}
	\label{fig:onecol}
\end{figure}
\begin{figure}[t]
	\begin{center}
		\fbox{\includegraphics[scale=1]{./images/gradcam}}
	\end{center}
	\caption{From left to right: \textbf{Original image, class: Target Spot}, \textbf{GradCAM of AlexNet pretrained on Original dataset}, \textbf{GradCAM of AlexNet pretrained on random background images}. It is possible to see the difference on the activation of GradCAM, one is distributed both on the leaf and on the background, the other is locate only on the leaf disease.}
	\label{fig:gradcam}
	\label{fig:long}
	\label{fig:onecol}
\end{figure}
