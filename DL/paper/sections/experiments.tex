\begin{figure*}
\begin{center}
\fbox{\includegraphics[scale=0.262]{./images/normal_3159}
	   \includegraphics[scale=0.262]{./images/segmented_3159}
	   \includegraphics[scale=0.35]{./images/9_ROTATE_180_crop}
	   \includegraphics[scale=0.262]{./images/196_ROTATE_270}
	   \includegraphics[scale=0.35]{./images/random_backgorund}
	   }
	\begin{center}
		\caption{Sampels of training images, from left to right: \textbf{Original PlantVillage dataset}, \textbf{Segmented PlantVillage dataset}, \textbf{Random background Crop dataset}, \textbf{Random Noise Backgorund} and \textbf{Random Background Image}}
		\label{fig:samples}
	\end{center}
	\vspace{-15pt}
\end{center}
\end{figure*}

\section{Experiments}
Our experiments are on two main task: Binary Classification, Multi-class Classification. In this section first we describe the dataset and the variations created to perform sensitivity analysis. Then we go trough the experiments setup were we describe how we have conducted the experiments to accomplish the two task and finally we show the results.

\subsection{Datasets}
We analyze 18158 images of tomato plant leaves, which are splitted in 10 classes, 9 diseases and 1 healthy. The scope is to predict the correct class of a leaf given its image. All the images are sized 256x256. 
\\\indent Given the original dataset we have conducted the training phase on different variations of the original dataset, we have worked on the background in order to find a way to overcome the limits highlined in \cite{} and confirmed by us.
In Figure \ref{fig:samples} we can see all the images the different versions of the dataset that we have tested and built.
\begin{itemize}
\item{\textbf{Original PlantVillage dataset} it consists of images of tomato leaves lain over a gray table.}
\item{\textbf{Segmented PlantVillage dataset} it consists of images of tomato leaves without the original background, this variation was used also in \cite{}. In our work we have re-segmented the images since in the available segmented dataset was not complete.}
\item{\textbf{Random Background Crop dataset} it consists of the leaf images coming from PlantVillage with a background composed of crops of background coming from the Original Plantvillage Dataset. We have tried this variation in order to exploit the dependence between original backgrounds and the class we found out in the experiment on the original dataset.}
\item{\textbf{Random Noise Backgorund} it consists of leaf images coming from PlantVillage with a background composed of random colored pixels. As before we tried this experiment to exploit the dependence between background and classes higlined in the original dataset.}
\item{\textbf{Random Background Image} it consists of leaf images coming form Plant Village with a background taken from a set of 4176 we built looking for tomato plantation images . The objective of this set was not only to exploit the backgorund influence on the classifier but also try to take the leaf in a situation similar to a realistic one, where the leaf image is taken directly in the plantation.}
\end{itemize}

\subsection{Experiments setup}
\subsubsection{Data Augmentation and Normalization}
As showed in Figure \ref{fig:1} after the Train-Test Split and Transformation Selection Phases our train set goes trough augmentation and normalization.
\\\indent We have performed data augmentation applying to the original sample two transformations from this pool:
Flip Top Bottom, 	Flip Left Right, Rotate 90\degree, Rotate 180\degree, Rotate 270\degree, Flip Top Bottom and Rotate 90\degree, Flip Top Bottom and Rotate 270\degree.
\\\indent After augmentation we have three samples for each original image (1 original image + 2 transformed images).
We have done this in order to train the networks with more data and strength the obtained model.
\\\indent Another key aspect of our setup is the normalization of the input images, the chosen normalization changes dramatically the validation accuracy. In our work we have explored the space of possible normalization considering these:
	\begin{itemize}
		\item{\textbf{Dataset Normalization} given the chosen variation of the dataset we have computed the mean and the standard deviation of the whole dataset.}
		\item{\textbf{Per-leaf Normalization} starting from the segmented dataset we have computed the mean and standard deviation of the non-black pixels.}
	\end{itemize}
\subsubsection{Binary Classification Setup}

\textbf{LeNet}
This network proposed in \cite{ref30} is one of the simplest deep model available. We have adapted it to perform our binary task. \\
\textbf{Weights Inizialization:}
for this network we started using training from scratch approach. The weights in the net are initialized using Xavier initialization \cite{ref31}. This helps training  since we start from a normally distribute set of weights and we avoid that certain weighs vanish trough epochs.
\\
\textbf{Activation Function:}
layers activation function is rectified linear unit (ReLU) since diminishes the likelihood of a gradient to vanish.
\\
\textbf{Loss Function:}
the chosen loss function for the binary classification is BCEWithLogitsLoss since it is designed for binary tasks and more stable compared to cross entropy.
\\
\textbf{Validation:}
for this task we have performed k-fold cross validation with k = 10 over the training set. This kind of validation was used to estimate the number of training epochs and the batch size to use.
\subsubsection{Multi-class Classification Setup}
\textbf{AlexNet}
for this task we have chosen a more complex model since we have tested LeNet over the ten class with results very far from the state of the art \cite{ref11}. In order to compare our results with \cite{ref11} we have chosen AlexNet.  \\
\textbf{Weights Inizialization:}
for this network we have tried both training from scratch approach and transfer learning. \\\indent The weights in the first case are initialized using Xavier initialization \cite{ref31}. This helps training  since we start from a normally distribute set of weights avoids that certain weighs vanish trough epochs.\\\indent In the transfer learning approach we have used the weights coming from the training on ImageNet \cite{imagenet}.
\\
\textbf{Activation Function:}
layers activation function is again rectified linear unit (ReLU).
\\
\textbf{Loss Function:}
in this case we have used Cross Entropy as loss function.
\\
\textbf{Validation:}
in the case of Multi-class Classification we opt to proceed with cross validation. We have chosen a different approach from binary classification. In fact k-fold cross validation applied on AlexNet requires a lot of computing time that is not justified in our dataset since there is small amount of variance in our pictures and consequently in each possible fold.
\\
\textbf{Optimizer:}
As optimizer we have choosen Adam \cite{ref32}. An important annotation should be done about this optimizer. In fact trough the training process we noticed that accuracy after a bunch of epochs drops. This was caused by the $\varepsilon$ coefficient, this coefficient used to avoid division by zero when the gradient is almost zero in parameters update.  By default is set to $1*10^{-8}$ and it causes large weights updates. So we set it to 0.1 to avoid this problem.

\begin{figure*}
\begin{center}
	\fbox{\includegraphics[scale=1.5]{./images/tensorboards}}
	\begin{center}
		\caption{Tensorboard graph of experiments, from left to right: \textbf{Validation Accurancy over epochs}, \textbf{Valdiation error over epochs}. }
		\label{fig:tensorboard}
	\end{center}
	\vspace{-15pt}
\end{center}
\end{figure*}

\subsection{Results and discussion}
\subsubsection{Binary Classification}
After a training phase using 10-fold cross validation, we have selected as best hyperparameters for our binary classification problem, the batch size equal to 32 and the total number of epochs equal to 15. With this configuration, after retraining the net on the global train set, we have obtained the results on the test set shown in the table \ref{table:binary}. Beeing a very unbalanced dataset because of the number of healthy leaves with respect to the non healthy ones, we have expected to have an healthy accurancy lower than non healthy. The result shows that our assumptions was correct. In fact LeNet accurancy for healthy aren't good as for non healthy one. By the way the average performances of our net are good.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|}
			\hline
			\textbf{Measure} & \textbf{Results} \\ 
			\hline
			$Average Accuracy$ & $0.999184$ \\
			$Healthy Accuracy$ & $0.996678$ \\
			$Non Healthy Accuracy$ & $0.999407$ \\
			$Precision_M$ & $0.993377$ \\
			$Recall_M$ & $0.996678$ \\
			$F_1 score_M$ & $0.995025$ \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Performance of binary classification.}
	\label{table:binary}
\end{table}
\subsubsection{Multi-class Classification}
As we have done for binary classification, we have tried different run using different hyperparameters and we test our result on the validation set. As figure \ref{fig:tensorboard} shows, it's possible to understand that the best configuration it has been given from Alexnet pretrained, with batch size equal to 64, eps equal to 0.1 for 57 epochs. The results obtained from this configuration are described in the first row of the table \ref{table:sensitivity}. AlexNet pretrained has a very good performance for all the classes and obtained also better result than the state of the art \cite{ref11}. We have expected that classes with less samples, e.g. Tomato Mosaic Virus, would have been missclassified compared to classes with an higher number of samples, e.g. Tomato Yellow Leaf Curl. This does not happen in the reality, because our classifier missclassified only some samples that aren't related to the size of the class predicted.
\subsubsection{Sensitivity Analisys}
After having reached a good level of accuracy for our multi-class classification task, we have moved our attention to analise the robustness of our dataset by computing gradcam and occlusion methods to analise which parts of the leaf trigger the classifier. The table \ref{table:sensitivity} shows all the different approach we have tried. It's possible to see that the preformances of the results obtained are very far from the what we have done in the previous task. Sometimes also happens that some classes have never be predicted at all. Then we have tried a different way, applying both normalization and backgrounds moving to something similar to what a predictor will see when it will applied on the field. Using per-leaf normalization and random background images we obtain the result shows in figure \ref{fig:conf_matrix}. It's also possible to see in figure \ref{fig:gradcam} how the system is more robust to some background variation, activating only on the leaf surface.
\begin{table}
	\centering
	\small
	\begin{center}
		\begin{tabular}{|p{1.5cm}|p{1.5cm}|c|}
			\hline
			Train & Test & Performance\\ 
			\hline
			\multirow{4}*{Original}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.998560$ \\
					$Precision_M = 0.998339$ \\
					$Recall_M = 0.998173$ \\
					$F_1 score_M = 0.998254$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.390169$ \\
				$Precision_M = NaN$ \\
				$Recall_M = 0.285877$ \\
				$F_1 score_M = Nan$ \\
				\end{tabular} \\  				
			\hline
			\multirow{4}*{Segmented}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.617933$ \\
					$Precision_M = 0.730197$ \\
					$Recall_M = 0.494125$ \\
					$F_1 score_M = 0.486940$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.966511$ \\
				$Precision_M = 0.959517$ \\
				$Recall_M = 0.956894$ \\
				$F_1 score_M = 0.958019$ \\
				\end{tabular} \\  				
			\hline
			\multirow{4}*{Random Background Crop}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.769175$ \\
					$Precision_M = 0.794344$ \\
					$Recall_M = 0.673085$ \\
					$F_1 score_M = 0.671527$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.848037$ \\
				$Precision_M = 0.885544$ \\
				$Recall_M = 0.737432$ \\
				$F_1 score_M = 0.739969$ \\
				\end{tabular} \\  				
			\hline
			\multirow{4}*{Random Noise Background}
			& Original & 
					\begin{tabular}{@{}c@{}}
					$Average Accuracy = 0.578862$ \\
					$Precision_M = 0.666754$ \\
					$Recall_M = 0.490099$ \\
					$F_1 score_M = 0.499304$ \\
					\end{tabular} \\
			\cline{2-3}
			& Segmented &
				\begin{tabular}{@{}c@{}}
				$Average Accuracy = 0.748469$ \\
				$Precision_M = 0.820938$ \\
				$Recall_M = 0.709873$ \\
				$F_1 score_M = 0.697417$ \\
				\end{tabular} \\  								
			\hline
		\end{tabular}
	\end{center}
	\caption{Performance of multi-class classification with difference training and test sets. We use a NaN value for the class that are never predicted to avoid division by zero in precision, recall and F1 score.}
	\label{table:sensitivity}
\end{table}
\begin{figure}[t]
	\begin{center}
		\fbox{\includegraphics[scale=0.3]{./images/conf_matrix_norm}}
	\end{center}
	\caption{Confusion matrix of AlexNet pretrained in multi-class classification problem in percentage using per-leaf normalization and random background images.}
	\label{fig:conf_matrix}
	\label{fig:long}
	\label{fig:onecol}
\end{figure}
\begin{figure}[t]
	\begin{center}
		\fbox{\includegraphics[scale=1]{./images/gradcam}}
	\end{center}
	\caption{From left to right: \textbf{Original image, class: Target Spot}, \textbf{GradCAM of AlexNet pretrained on Original dataset}, \textbf{GradCAM of AlexNet pretrained on random background images}. It is possible to see the difference on the activation of GradCAM, one is distributed both on the leaf and on the background, the other is locate only on the leaf disease.}
	\label{fig:gradcam}
	\label{fig:long}
	\label{fig:onecol}
\end{figure}
