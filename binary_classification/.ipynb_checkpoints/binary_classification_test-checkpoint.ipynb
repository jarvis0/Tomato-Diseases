{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "wd = 0\n",
    "\n",
    "binary_classification = True\n",
    "if binary_classification:\n",
    "    classes = ['healthy', 'non_healthy']\n",
    "else:  \n",
    "    classes = ['healthy', 'Bacterial_spot', 'Early_blight', 'Late_blight', 'Leaf_Mold', 'Septoria_leaf_spot',\n",
    "           'Spider_mites Two-spotted_spider_mite', 'Target_Spot', 'Tomato_mosaic_virus', 'Tomato_Yellow_Leaf_Curl_Virus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(filename, to_file):\n",
    "    f = open(filename, 'a+')\n",
    "    f.write(str(to_file))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = '../augmented_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.44947562, 0.46524084, 0.40037745]\n",
    "std = [0.18456618, 0.16353698, 0.20014246]\n",
    "\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)]),\n",
    "        'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                    data_transforms[x]) for x in ['train', 'test']}\n",
    "\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # 3 input image channel,\n",
    "        # 6 output channel,\n",
    "        # 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation\n",
    "        self.fc1 = nn.Linear(16 * 61 * 61, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.conv1.weight)\n",
    "        nn.init.xavier_normal_(self.conv2.weight)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # max pooling over a (2, 2) windows\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    \n",
    "epoch_progress = trange(num_epochs, bar_format='{desc}{r_bar}')\n",
    "for epoch in epoch_progress:  # loop over the dataset multiple epochs\n",
    "\n",
    "    # iterate over the data\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "\n",
    "        # get the inputs\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "\n",
    "        # forward + loss\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.BCEWithLogitsLoss()(outputs.view(-1), labels.float())\n",
    "                \n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step() # does the update\n",
    "\n",
    "print('K-fold cross-validation is over.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        total += labels.size(0)\n",
    "        preds = torch.round(F.sigmoid(outputs))\n",
    "        correct += torch.sum(preds.view(-1) == labels.data.float())\n",
    "\n",
    "save_to_file('test_performances', 'Accuracy of the network on the test images: {} %%'.format((100 * correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.round(F.sigmoid(outputs))\n",
    "        c = (preds.view(-1) == labels.data.float()).squeeze()\n",
    "        for i in range(len(classes)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(len(classes)):    \n",
    "    save_to_file('test_performances', '\\nAccuracy of {}: {} %'.format(classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
